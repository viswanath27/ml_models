{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOVIE REVIEW USING TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP for the IMDB problem\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEE DATA SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK THE CLASSES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is binary classification problem for the sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# Summarize number of classes\n",
    "print(\"Classes: \")\n",
    "print(numpy.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODED DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here encoding is done for the text data and also will collect the highest frequent top 1000 words. This is majorly need to expand in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "       list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "       list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is showing the total number of unique words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# Summarize number of words\n",
    "print(\"Number of words: \")\n",
    "print(len(numpy.unique(numpy.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "...\n",
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings is the words are encoded as the vectors in the real world based on the meaning of the word. Similarity in the meaning translates to the closer word spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 1225, 446, 2, 45, 2174, 84, 2, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 2, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 2, 5, 4241, 18, 4, 2, 2, 250, 11, 1818, 2, 4, 4217, 2, 747, 1115, 372, 1890, 1006, 541, 2, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "         list([1, 1446, 2, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 2, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 2, 2, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 2, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 1668, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 2, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 2, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 2, 2, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 2, 185, 132, 1988, 2, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 2, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 2, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 2, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 2, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 2, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 2, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 1239, 2, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 2, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 2, 2, 3292, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 2, 2, 4, 4770, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 2, 5, 2, 68, 1830, 19, 2, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 2, 2, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 2, 7, 15, 2, 2, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 2, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 2, 9, 133, 1810, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 2, 3406, 718, 2, 9, 6, 2, 17, 210, 5, 3281, 2, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 1441, 2, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "...\n",
    "imdb.load_data(nb_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7fbe68aaba58>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding(5000, 32, input_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 0.5286 - accuracy: 0.6926 - val_loss: 0.3014 - val_accuracy: 0.8698\n",
      "Epoch 2/2\n",
      " - 2s - loss: 0.2000 - accuracy: 0.9224 - val_loss: 0.3272 - val_accuracy: 0.8638\n",
      "Accuracy: 86.38%\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
